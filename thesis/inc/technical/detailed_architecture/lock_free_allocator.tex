\subsection{Lock-Free Allocator}
\label{subsec:detailed_lock_free_allocator}
The lock-free allocator is a linear allocator built with a linked list of memory blocks.
It was introduced into the NOX ECS to support dynamic allocation mainly for the event system. However, it was soon used for other systems as well, as the queuing mechanisms in the entity manager.

\subsubsection{Explanation}
\paragraph{Linear Allocators}
As mentioned earlier the allocator is a linear allocator, which means that while the allocator supports allocations of many different sizes,
it only supports mass deallocation, i.e. freeing all memory at once, which is not possible to do concurrently.
This decision was intentionally made to keep the functionality of the allocator as simple as possible, to allow for a lock-free implementation.
Another rationale for the decision to go for a linear allocator was that this allocator is usually used for read-only objects with a short lifetime, like events or transition requests.
These objects only live for a single iteration of the update loop and are all destroyed at the same location, meaning that the support for individual deallocation is not needed.

\paragraph{Linked List}
The idea behind the allocator is simply a singly linked list consisting of memory blocks, with a pointer to the beginning and a pointer to the first memory block with free memory available.
These memory blocks consist of a pointer to the next block, a fixed size byte buffer and a variable to indicate the amount of memory used within the buffer.
Of the two pointers in the linked list, the only one of real importance is the pointer to the first
memory block that is free. 
The pointer to the beginning of the list mainly exists to allow for proper cleanup of the list during its destruction and to reset the first free pointer when clearing the allocator.
The allocator reuses the memory stored within the list after a clear operation, and therefore only
allocates more memory if needed.

\paragraph{Allocation - Single threaded}
Allocating memory in a single threaded environment is a trivial matter, when an allocation is requested one check if there is enough room within the first free memory block.
If it is not sufficient for an allocation, one either uses a previously allocated free block if possible or allocate a new block and appending it to the list, as seen is listing\ref{lst:single_threaded_allocate}, before updating the blocks size and returning the memory to the caller.
\lstinputlisting[language=cpp, caption=allocate single threaded, label=lst:single_threaded_allocate]{lock_free_allocator_code/single_threaded_allocate.py}

\paragraph{Allocation - Lock Free}
The lock-free implementation of the allocation function is a bit more involved than the single threaded version and requires more steps, detailed in the following section. 
The memory ordering constraints placed on atomic operations is omitted both for the sake of brevity, and because they are not fundamental to the algorithm.
The whole procedure with memory ordering constraints can be seen in the project repository.

\subparagraph{Compare and Swap}
The main idea behind the lock free implementation is that each thread that requests an allocation will do some speculative work, based on its view of the allocator's state. 
When this work is done, the thread will try to publish its work to the other threads, which is possible only if its earlier view of the allocator's state has not changed.
This behavior is achieved through compare and swap functionality\footnote{Aka. CAS or compare\_exchange in C++11}, which is a function that compares an atomic value with an expected value, and if these two values are equal, the atomic value is replaced with the desired value.
Otherwise, the expected value is updated to the current value of the atomic object. 
The compare and swap boils down to an atomic execution of the code seen in listing \ref{lst:compare_and_swap}.
The compare and swap functionality is vital for the algorithm, as it allows each thread to know not only the updated state of the allocator, but also whether or not they were the ones who updated it.
\lstinputlisting[language=cpp, caption=compare and swap, label=lst:compare_and_swap]{lock_free_allocator_code/compare_and_swap.py}

\subparagraph{Allocate}
There are two main steps to the allocation; the main allocation step, and try allocate step.
The main allocation step is the most complicated of these two, and deals with the possible problem of creating or reusing a memory block within the linked list.
The function starts by trying to allocate using the memory block indicated by the first free pointer, returning the newly allocated memory if successful.
In the case of a failure, the function will try to change the first free pointer, to point to either a reusable memory block or an entirely new block.
In the latter situation, the allocation of a new block must be noted, as if it is not attached to the list, it needs to be freed.
At this point, the current thread will attempt to publish its change of the first free pointer, done through a compare and swap instruction.
If the compare and swap instruction is successful, then the new block is attached to the list, and the one tried to allocate using the newly attached block, returning on success.
Allocation failure can happen if some other threads have entirely filled up the newly attached blocks, in this case, the whole allocation procedure will need to go back to start and retry the whole routine, which is also the case if the compare and swap instruction fails.
The pseudo code for the algorithm can be seen in listing \ref{lst:allocate}.
\lstinputlisting[language=cpp, caption=allocate, label=lst:allocate]{lock_free_allocator_code/lock_free_allocate.py}

\subparagraph{Try Allocate}
The try allocate function is a bit simpler than the previous step. The function tries to allocate
a memory segment within the block provided as a parameter.
The function simply tries to reserve a piece of memory by increasing the number of bytes used within the block.
If there is not enough room, the function will return a nullptr, indicating that an allocation was not possible within the suggested block.
The increase in the number of bytes used within the block is done through a compare and swap function.
If the current thread running the function is the one that is allowed to increase the number of bytes in the block, it returns newly reserved memory.
In the case where the current thread did not successfully change the number of bytes used variable, it will have to reload that variable and retry the whole function.
The pseudo code for this function can be seen in listing \ref{lst:try_allocate}
\lstinputlisting[language=cpp, caption=allocate, label=lst:try_allocate]{lock_free_allocator_code/lock_free_try_allocate.py}

\phantomsection
\subparagraph{Circumventing the ABA Problem}
\label{subpar:detailed_lock_free_allocator_aba}
A challenging issue in the topic of lock-free programming based on compare and swap functionality is the ABA problem.
The ABA problem in lock-free programming is a false positive situation in a compare and swap\cite{understanding_and_preventing_aba_problem}.
The situation occurs when a thread \textit{t1} reads an expected value \textit{v} from memory,
which will be used in a compare and swap instruction, but before
the compare and swap instruction is executed \textit{t1} is interrupted.
Another thread \textit{t2} is executed and does its work, changing the state \textit{v}.
However, when \textit{t2} is finished with its work, the value of \textit{v} is the same as what \textit{t1} read.
In this case, when \textit{t1} continues to run, it will be unaware of the modifications \textit{v} went through
when \textit{t2} was executing, and perceive the state as unchanged.

When creating the allocator it was known that other lock-free structures would use it, like the stack, and those implementations would often use raw atomic pointers.
The ABA problem will only arise if the collection is given a piece of memory it has seen before while pushing or popping concurrently.
Disallowing the possibility of reusing memory in the concurrent setting was an easy way of circumventing that problem.

\subsubsection{Motivation of Lock-Free Allocator}
Many factors influenced the decision to create this allocator structure.

\paragraph{Context Switch}
One of the issues with the standard heap allocation operations in C++ is that on a lot of operating systems requests for memory allocations, which leads to a context switch into
kernel mode and back to user mode, this is also the case for deallocation.
The context switch can be a very costly operation and should be avoided if possible, especially in performance intensive parts of the program\cite[p. 240]{game_engine_architecture}.
A way to avoid this context switch is to reuse memory, which can be done by allocating
chunks of memory up front, and allocating into that instead.


\paragraph{Avoiding Locking}
The allocator was supposed to be used in a multi-threaded environment, where multiple threads
should be able to allocate from the same allocator.
Having shared mutable state between threads means that some protection is needed
to avoid race condition problems.
One solution would be a mutual exclusion strategy, locking access to the allocator state through a mutex.
However, this approach can be quite costly, especially in systems where there will be high contention, as the event system.
It was therefore decided that it is better to go with an atomic lock-free approach to the allocator.

\paragraph{Performance on Weakly Ordered Systems}
The other rationale for the lock-free structure is to increase performance on weakly ordered systems, like ARM architectures\cite{preshing_weak_vs_strong_memory_models}.
Working with low-level atomics in C++ allows for the specification of memory ordering constraints, which can be used to improve performance on the weakly ordered systems.

\paragraph{Pointer Invalidation}
Seeing as the allocator would be accessed from different threads concurrently, it was important that memory would not be reallocated, as this would destroy references to objects within the allocated memory.
This problem is what motivated the linked list approach of the allocator, which allows for insertion of elements without the need for reallocation.

\subsubsection{Alternatives to Lock-Free Allocator}
\label{subsubsec:lock_free_allocator_alternatives}
Probably best alternative solution would be to give each thread their own allocator.
This solution would ease the synchronization and protection requirements, as no data would need to be shared between threads, at least until the data has to be processed by another procedure.
Having one allocator per thread could also solve potential cache ping-ponging\footnote{Explained in p.\pageref{par:detailed_lock_free_ping_pong}} and false sharing issues, as these allocators would just need to be aligned in a way that would guarantee that false sharing would not take place.
In hindsight this would possibly have been a better solution than the one chosen, it would probably be easier to implement as well.

\subsubsection{Pros of Lock Free Allocator}
While there are many cons with the lock-free allocator, it does come with certain pros.

\paragraph{Lock Impossibility}
Because of the lack of exclusive ownership within the allocator, the system is guaranteed to neither livelock or deadlock.
Deadlocking should not be possible with a locked implementation either, as the allocator is only locking at the lowest level.

\paragraph{Guaranteed Progress}
The lock-free allocator guarantees system-wide progress, meaning that even if one thread might have to redo their speculative work within the algorithm, another thread will make decent progress.

\paragraph{Context Switch Minimization}
The allocator avoids a lot of context switching by reusing the memory within the linked list.
Currently, the allocator will only context switch to allocate new memory when the allocator needs to request a new block,
because it does not have any memory to reuse.

\subsubsection{Cons of Lock-Free Allocator}
While there are certain pros to this solution, there are many cons.

\paragraph{Maintainability}
Lock-free programming is quite challenging, even more so when working with non-sequential consistent atomics.
It also requires the understanding of some pretty advanced and low-level topics, like compile-time and run-time instruction reordering.
Lock-free algorithms require the programmer to think of all the different ways the execution of a program can be interleaved between the various threads.
Hidden bugs might only be noticeable on certain architectures, or only in release builds.
Printing out variables might cause a bug to disappear, as the print statement creates a synchronization point.
All of these points leads to code that is hard to maintain, which is not desirable within a code base.

\paragraph{Fragmentation}
If a memory block cannot accommodate an allocation request of a certain size, then a new memory block will be allocated, and the first free pointer will be updated to this new block.
There might still be a lot of memory free within the previous block, which could have been used for smaller allocations.
However, with the current implementation of the allocator, this memory is just discarded, leading to a lot of internal memory fragmentation.
This behavior is arguably not a huge problem, as the fragmentation is short lived, and the extra memory allocated to deal with the fragmentation
will be reused next frame.
The memory could be better utilized by for example having a pointer to the first memory block with any free memory, and from that point look for the first memory block that could accommodate a specific allocation request. However, this would add extra overhead to the allocation function.

\paragraph{No Shrinking Functionality}
The current implementation of the allocator does not allow for any shrinking functionality, which means that the allocator never deallocates any blocks from its linked list.
It would be desirable to have a shrink to fit like functionality that allows the allocator to have a minimum working set, that could dynamically expand and shrink to fit the need of the allocator.
The functionality does not need to be complex, it could simply be used to keep an average number of needed memory blocks over a certain number of frames, and deallocate any memory blocks that is unnecessary based on that average.

\paragraph{Allocation Heavy During Startup}
The implementation of the allocator will do a lot of heap allocation when new blocks need to be added to the list of memory blocks.
This is because each thread will be allocating a memory block, which they will try to add to the list.
Often these allocations will be unused, which is the case when a thread is not allowed to update the first pointer but allowed to allocate into it.
However, this case does not happen particularly often, as the allocator quickly starts reusing its memory, and the situation will only occur when
the linked list needs to be expanded.

\phantomsection
\paragraph{Cache Ping Pong}
\label{par:detailed_lock_free_ping_pong}
Williams\cite{williams_safety_off} describes cache ping pong as the situation where two processors are accessing either the same atomic variable or a different atomic variable on the same cache line.
This behavior results in the cache lines being shuffled back and forth between the processors, which is not good for performance.
Our implementation of the lock-free allocator falls into the trap of allowing cache ping pong.
As several threads can operate on the same memory within a memory block, updating a memory block's number of used bytes, or
potentially trying to update the first free memory block pointer.
Currently, no efforts are put in place to mitigate these issues, as they were not known during its implementation.
